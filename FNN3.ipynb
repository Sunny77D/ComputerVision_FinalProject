{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#our additions\n",
    "import json\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset previously downloaded from Kaggle\n",
    "NUMBER_CLASSES = 10\n",
    "\n",
    "def load_train():\n",
    "    start_time = time.time()\n",
    "    train_pose = [] \n",
    "    train_labels = []\n",
    "    # Loop over the training folder \n",
    "    for classed in tqdm(range(NUMBER_CLASSES)):\n",
    "        print('Loading directory c{}'.format(classed))\n",
    "        files = glob(os.path.join('..', 'sample_json', 'c' + str(classed), '*.json'))\n",
    "        for file in files:\n",
    "            jsonFile = open(file, 'r')\n",
    "            try: \n",
    "                values = json.load(jsonFile)['people'][0]['pose_keypoints_2d']\n",
    "            except IndexError: \n",
    "                continue\n",
    "            #print(values)\n",
    "            #print(len(values))\n",
    "            train_pose.append(values)\n",
    "            train_labels.append(classed)\n",
    "    print(\"Data Loaded in {} second\".format(time.time() - start_time))\n",
    "    return train_pose, train_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:00<00:03,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:00<00:02,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:01<00:02,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:01<00:02,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:01<00:01,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:02<00:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:02<00:01,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:02<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:03<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded in 3.434006929397583 second\n"
     ]
    }
   ],
   "source": [
    "train_pose, train_labels = load_train()\n",
    "# train_labels            = np_utils.to_categorical(train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22394\n",
      "22394\n"
     ]
    }
   ],
   "source": [
    "print(len(train_pose))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly assign train and validation sets 80/20 split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_pose, train_labels, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 3, 4, 2, 1, 2, 3, 0, 8]\n"
     ]
    }
   ],
   "source": [
    "print((Y_train[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.Linear(75, 50)\n",
    "        self.hidden2 = nn.Linear(50, 25)\n",
    "        self.output = nn.Linear(25, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.Linear(75, 150)\n",
    "        self.hidden2 = nn.Linear(150, 100)\n",
    "        self.hidden3 = nn.Linear(100, 30)\n",
    "        self.output = nn.Linear(30, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh    = nn.Tanh() \n",
    "        \n",
    "    def forward(self, x, cnn_data):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = F.tanh(x)\n",
    "        x = np.concatenate((x, cnn_data), axis=1)\n",
    "        x = np.hidden4(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] loss: 41.193\n",
      "[Epoch: 2] loss: 40.841\n",
      "[Epoch: 3] loss: 40.501\n",
      "[Epoch: 4] loss: 40.110\n",
      "[Epoch: 5] loss: 39.549\n",
      "[Epoch: 6] loss: 38.738\n",
      "[Epoch: 7] loss: 37.520\n",
      "[Epoch: 8] loss: 35.887\n",
      "[Epoch: 9] loss: 34.126\n",
      "[Epoch: 10] loss: 32.552\n",
      "[Epoch: 11] loss: 31.257\n",
      "[Epoch: 12] loss: 30.198\n",
      "[Epoch: 13] loss: 29.322\n",
      "[Epoch: 14] loss: 28.544\n",
      "[Epoch: 15] loss: 27.792\n",
      "[Epoch: 16] loss: 27.082\n",
      "[Epoch: 17] loss: 26.336\n",
      "[Epoch: 18] loss: 25.595\n",
      "[Epoch: 19] loss: 24.766\n",
      "[Epoch: 20] loss: 23.894\n",
      "[Epoch: 21] loss: 23.028\n",
      "[Epoch: 22] loss: 22.175\n",
      "[Epoch: 23] loss: 21.309\n",
      "[Epoch: 24] loss: 20.590\n",
      "[Epoch: 25] loss: 20.004\n",
      "[Epoch: 26] loss: 19.452\n",
      "[Epoch: 27] loss: 18.918\n",
      "[Epoch: 28] loss: 18.502\n",
      "[Epoch: 29] loss: 18.120\n",
      "[Epoch: 30] loss: 17.823\n",
      "[Epoch: 31] loss: 17.383\n",
      "[Epoch: 32] loss: 16.962\n",
      "[Epoch: 33] loss: 16.678\n",
      "[Epoch: 34] loss: 16.392\n",
      "[Epoch: 35] loss: 16.021\n",
      "[Epoch: 36] loss: 15.710\n",
      "[Epoch: 37] loss: 15.411\n",
      "[Epoch: 38] loss: 15.560\n",
      "[Epoch: 39] loss: 15.474\n",
      "[Epoch: 40] loss: 15.270\n",
      "batch size: 100\n",
      "[Epoch: 41] loss: 14.094\n",
      "[Epoch: 42] loss: 13.650\n",
      "[Epoch: 43] loss: 13.392\n",
      "[Epoch: 44] loss: 13.322\n",
      "[Epoch: 45] loss: 13.160\n",
      "[Epoch: 46] loss: 12.992\n",
      "[Epoch: 47] loss: 12.812\n",
      "[Epoch: 48] loss: 12.773\n",
      "[Epoch: 49] loss: 12.674\n",
      "[Epoch: 50] loss: 12.575\n",
      "[Epoch: 51] loss: 12.485\n",
      "[Epoch: 52] loss: 12.294\n",
      "[Epoch: 53] loss: 12.280\n",
      "[Epoch: 54] loss: 12.114\n",
      "[Epoch: 55] loss: 11.967\n",
      "[Epoch: 56] loss: 11.905\n",
      "[Epoch: 57] loss: 12.022\n",
      "[Epoch: 58] loss: 11.814\n",
      "[Epoch: 59] loss: 11.720\n",
      "[Epoch: 60] loss: 11.894\n",
      "[Epoch: 61] loss: 11.691\n",
      "[Epoch: 62] loss: 11.724\n",
      "[Epoch: 63] loss: 11.709\n",
      "[Epoch: 64] loss: 11.698\n",
      "[Epoch: 65] loss: 11.762\n",
      "[Epoch: 66] loss: 11.558\n",
      "[Epoch: 67] loss: 11.478\n",
      "[Epoch: 68] loss: 11.317\n",
      "[Epoch: 69] loss: 11.326\n",
      "[Epoch: 70] loss: 11.166\n",
      "[Epoch: 71] loss: 11.106\n",
      "[Epoch: 72] loss: 11.182\n",
      "[Epoch: 73] loss: 11.126\n",
      "[Epoch: 74] loss: 11.023\n",
      "[Epoch: 75] loss: 11.057\n",
      "[Epoch: 76] loss: 11.124\n",
      "[Epoch: 77] loss: 11.196\n",
      "[Epoch: 78] loss: 10.769\n",
      "[Epoch: 79] loss: 10.727\n",
      "[Epoch: 80] loss: 10.801\n",
      "batch size: 200\n",
      "[Epoch: 81] loss: 10.235\n",
      "[Epoch: 82] loss: 10.054\n",
      "[Epoch: 83] loss: 9.963\n",
      "[Epoch: 84] loss: 9.899\n",
      "[Epoch: 85] loss: 9.803\n",
      "[Epoch: 86] loss: 9.797\n",
      "[Epoch: 87] loss: 9.703\n",
      "[Epoch: 88] loss: 9.670\n",
      "[Epoch: 89] loss: 9.683\n",
      "[Epoch: 90] loss: 9.657\n",
      "[Epoch: 91] loss: 9.598\n",
      "[Epoch: 92] loss: 9.504\n",
      "[Epoch: 93] loss: 9.473\n",
      "[Epoch: 94] loss: 9.476\n",
      "[Epoch: 95] loss: 9.481\n",
      "[Epoch: 96] loss: 9.412\n",
      "[Epoch: 97] loss: 9.406\n",
      "[Epoch: 98] loss: 9.361\n",
      "[Epoch: 99] loss: 9.281\n",
      "[Epoch: 100] loss: 9.254\n",
      "[Epoch: 101] loss: 9.197\n",
      "[Epoch: 102] loss: 9.228\n",
      "[Epoch: 103] loss: 9.151\n",
      "[Epoch: 104] loss: 9.118\n",
      "[Epoch: 105] loss: 9.145\n",
      "[Epoch: 106] loss: 9.080\n",
      "[Epoch: 107] loss: 9.086\n",
      "[Epoch: 108] loss: 8.995\n",
      "[Epoch: 109] loss: 9.033\n",
      "[Epoch: 110] loss: 8.954\n",
      "[Epoch: 111] loss: 8.911\n",
      "[Epoch: 112] loss: 8.918\n",
      "[Epoch: 113] loss: 8.874\n",
      "[Epoch: 114] loss: 8.869\n",
      "[Epoch: 115] loss: 8.826\n",
      "[Epoch: 116] loss: 8.841\n",
      "[Epoch: 117] loss: 8.780\n",
      "[Epoch: 118] loss: 8.780\n",
      "[Epoch: 119] loss: 8.729\n",
      "[Epoch: 120] loss: 8.704\n",
      "batch size: 400\n",
      "[Epoch: 121] loss: 8.513\n",
      "[Epoch: 122] loss: 8.475\n",
      "[Epoch: 123] loss: 8.440\n",
      "[Epoch: 124] loss: 8.414\n",
      "[Epoch: 125] loss: 8.394\n",
      "[Epoch: 126] loss: 8.394\n",
      "[Epoch: 127] loss: 8.368\n",
      "[Epoch: 128] loss: 8.345\n",
      "[Epoch: 129] loss: 8.332\n",
      "[Epoch: 130] loss: 8.337\n",
      "[Epoch: 131] loss: 8.314\n",
      "[Epoch: 132] loss: 8.294\n",
      "[Epoch: 133] loss: 8.276\n",
      "[Epoch: 134] loss: 8.271\n",
      "[Epoch: 135] loss: 8.239\n",
      "[Epoch: 136] loss: 8.239\n",
      "[Epoch: 137] loss: 8.232\n",
      "[Epoch: 138] loss: 8.227\n",
      "[Epoch: 139] loss: 8.195\n",
      "[Epoch: 140] loss: 8.180\n",
      "[Epoch: 141] loss: 8.161\n",
      "[Epoch: 142] loss: 8.177\n",
      "[Epoch: 143] loss: 8.149\n",
      "[Epoch: 144] loss: 8.139\n",
      "[Epoch: 145] loss: 8.125\n",
      "[Epoch: 146] loss: 8.115\n",
      "[Epoch: 147] loss: 8.101\n",
      "[Epoch: 148] loss: 8.092\n",
      "[Epoch: 149] loss: 8.085\n",
      "[Epoch: 150] loss: 8.078\n",
      "[Epoch: 151] loss: 8.058\n",
      "[Epoch: 152] loss: 8.043\n",
      "[Epoch: 153] loss: 8.027\n",
      "[Epoch: 154] loss: 8.031\n",
      "[Epoch: 155] loss: 8.008\n",
      "[Epoch: 156] loss: 7.988\n",
      "[Epoch: 157] loss: 7.989\n",
      "[Epoch: 158] loss: 7.962\n",
      "[Epoch: 159] loss: 7.954\n",
      "[Epoch: 160] loss: 7.937\n",
      "batch size: 800\n",
      "[Epoch: 161] loss: 8.034\n",
      "[Epoch: 162] loss: 8.010\n",
      "[Epoch: 163] loss: 7.994\n",
      "[Epoch: 164] loss: 7.984\n",
      "[Epoch: 165] loss: 7.974\n",
      "[Epoch: 166] loss: 7.965\n",
      "[Epoch: 167] loss: 7.955\n",
      "[Epoch: 168] loss: 7.944\n",
      "[Epoch: 169] loss: 7.932\n",
      "[Epoch: 170] loss: 7.921\n",
      "[Epoch: 171] loss: 7.913\n",
      "[Epoch: 172] loss: 7.906\n",
      "[Epoch: 173] loss: 7.900\n",
      "[Epoch: 174] loss: 7.893\n",
      "[Epoch: 175] loss: 7.884\n",
      "[Epoch: 176] loss: 7.875\n",
      "[Epoch: 177] loss: 7.868\n",
      "[Epoch: 178] loss: 7.862\n",
      "[Epoch: 179] loss: 7.856\n",
      "[Epoch: 180] loss: 7.850\n",
      "[Epoch: 181] loss: 7.842\n",
      "[Epoch: 182] loss: 7.839\n",
      "[Epoch: 183] loss: 7.833\n",
      "[Epoch: 184] loss: 7.824\n",
      "[Epoch: 185] loss: 7.818\n",
      "[Epoch: 186] loss: 7.810\n",
      "[Epoch: 187] loss: 7.804\n",
      "[Epoch: 188] loss: 7.796\n",
      "[Epoch: 189] loss: 7.790\n",
      "[Epoch: 190] loss: 7.783\n",
      "[Epoch: 191] loss: 7.777\n",
      "[Epoch: 192] loss: 7.771\n",
      "[Epoch: 193] loss: 7.765\n",
      "[Epoch: 194] loss: 7.759\n",
      "[Epoch: 195] loss: 7.753\n",
      "[Epoch: 196] loss: 7.747\n",
      "[Epoch: 197] loss: 7.740\n",
      "[Epoch: 198] loss: 7.731\n",
      "[Epoch: 199] loss: 7.722\n",
      "[Epoch: 200] loss: 7.715\n",
      "batch size: 800\n",
      "[Epoch: 201] loss: 7.709\n",
      "[Epoch: 202] loss: 7.703\n",
      "[Epoch: 203] loss: 7.697\n",
      "[Epoch: 204] loss: 7.691\n",
      "[Epoch: 205] loss: 7.684\n",
      "[Epoch: 206] loss: 7.678\n",
      "[Epoch: 207] loss: 7.672\n",
      "[Epoch: 208] loss: 7.667\n",
      "[Epoch: 209] loss: 7.661\n",
      "[Epoch: 210] loss: 7.656\n",
      "[Epoch: 211] loss: 7.650\n",
      "[Epoch: 212] loss: 7.645\n",
      "[Epoch: 213] loss: 7.640\n",
      "[Epoch: 214] loss: 7.635\n",
      "[Epoch: 215] loss: 7.630\n",
      "[Epoch: 216] loss: 7.625\n",
      "[Epoch: 217] loss: 7.619\n",
      "[Epoch: 218] loss: 7.614\n",
      "[Epoch: 219] loss: 7.608\n",
      "[Epoch: 220] loss: 7.603\n",
      "[Epoch: 221] loss: 7.598\n",
      "[Epoch: 222] loss: 7.589\n",
      "[Epoch: 223] loss: 7.583\n",
      "[Epoch: 224] loss: 7.577\n",
      "[Epoch: 225] loss: 7.570\n",
      "[Epoch: 226] loss: 7.564\n",
      "[Epoch: 227] loss: 7.559\n",
      "[Epoch: 228] loss: 7.553\n",
      "[Epoch: 229] loss: 7.547\n",
      "[Epoch: 230] loss: 7.541\n",
      "[Epoch: 231] loss: 7.535\n",
      "[Epoch: 232] loss: 7.530\n",
      "[Epoch: 233] loss: 7.524\n",
      "[Epoch: 234] loss: 7.519\n",
      "[Epoch: 235] loss: 7.514\n",
      "[Epoch: 236] loss: 7.508\n",
      "[Epoch: 237] loss: 7.503\n",
      "[Epoch: 238] loss: 7.497\n",
      "[Epoch: 239] loss: 7.492\n",
      "[Epoch: 240] loss: 7.486\n",
      "batch size: 800\n",
      "[Epoch: 241] loss: 7.481\n",
      "[Epoch: 242] loss: 7.475\n",
      "[Epoch: 243] loss: 7.469\n",
      "[Epoch: 244] loss: 7.464\n",
      "[Epoch: 245] loss: 7.458\n",
      "[Epoch: 246] loss: 7.453\n",
      "[Epoch: 247] loss: 7.448\n",
      "[Epoch: 248] loss: 7.444\n",
      "[Epoch: 249] loss: 7.439\n",
      "[Epoch: 250] loss: 7.434\n",
      "[Epoch: 251] loss: 7.428\n",
      "[Epoch: 252] loss: 7.423\n",
      "[Epoch: 253] loss: 7.418\n",
      "[Epoch: 254] loss: 7.412\n",
      "[Epoch: 255] loss: 7.407\n",
      "[Epoch: 256] loss: 7.401\n",
      "[Epoch: 257] loss: 7.395\n",
      "[Epoch: 258] loss: 7.390\n",
      "[Epoch: 259] loss: 7.384\n",
      "[Epoch: 260] loss: 7.378\n",
      "[Epoch: 261] loss: 7.373\n",
      "[Epoch: 262] loss: 7.368\n",
      "[Epoch: 263] loss: 7.363\n",
      "[Epoch: 264] loss: 7.358\n",
      "[Epoch: 265] loss: 7.353\n",
      "[Epoch: 266] loss: 7.349\n",
      "[Epoch: 267] loss: 7.347\n",
      "[Epoch: 268] loss: 7.343\n",
      "[Epoch: 269] loss: 7.336\n",
      "[Epoch: 270] loss: 7.329\n",
      "[Epoch: 271] loss: 7.322\n",
      "[Epoch: 272] loss: 7.317\n",
      "[Epoch: 273] loss: 7.311\n",
      "[Epoch: 274] loss: 7.307\n",
      "[Epoch: 275] loss: 7.302\n",
      "[Epoch: 276] loss: 7.298\n",
      "[Epoch: 277] loss: 7.292\n",
      "[Epoch: 278] loss: 7.285\n",
      "[Epoch: 279] loss: 7.279\n",
      "[Epoch: 280] loss: 7.272\n",
      "batch size: 800\n",
      "[Epoch: 281] loss: 7.266\n",
      "[Epoch: 282] loss: 7.260\n",
      "[Epoch: 283] loss: 7.254\n",
      "[Epoch: 284] loss: 7.248\n",
      "[Epoch: 285] loss: 7.243\n",
      "[Epoch: 286] loss: 7.237\n",
      "[Epoch: 287] loss: 7.232\n",
      "[Epoch: 288] loss: 7.227\n",
      "[Epoch: 289] loss: 7.224\n",
      "[Epoch: 290] loss: 7.221\n",
      "[Epoch: 291] loss: 7.210\n",
      "[Epoch: 292] loss: 7.206\n",
      "[Epoch: 293] loss: 7.203\n",
      "[Epoch: 294] loss: 7.197\n",
      "[Epoch: 295] loss: 7.192\n",
      "[Epoch: 296] loss: 7.187\n",
      "[Epoch: 297] loss: 7.181\n",
      "[Epoch: 298] loss: 7.176\n",
      "[Epoch: 299] loss: 7.171\n",
      "[Epoch: 300] loss: 7.165\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#test variable batch size\n",
    "batch_size = 50\n",
    "epochs = 300\n",
    "track_loss = []\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    if epoch > 0 and epoch%40==0:\n",
    "        if batch_size < 800:\n",
    "            batch_size *= 2\n",
    "        print(\"batch size:\", batch_size)\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # print(i)\n",
    "        inputs = torch.FloatTensor(X_train[i:i+batch_size])\n",
    "        labels = torch.LongTensor(Y_train[i:i+batch_size])\n",
    "        \n",
    "        # print(labels)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    track_loss.append(running_loss * batch_size / 1000)\n",
    "    print('[Epoch: %d] loss: %.3f' % (epoch + 1, running_loss * batch_size / 1000))\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pose Training loss')"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3hddZ3v8fc3O5ed5p4maUPTNi0FKba0QCkIioyIQgcFFUcQGJyjgzOj59HzOOOgzhx1xnPEGdFxnCOKwFiVURlQYVCRi6IwCG0opS0tpaUtvdAmKb3k0tz39/yxV9pQkjZJs/baO+vzep797L3XXmuv78pqP7+1f+tm7o6IiMRHXtQFiIhIZin4RURiRsEvIhIzCn4RkZhR8IuIxIyCX0QkZhT8IuNgZgkz6zCzWRM57jjq+JKZfW+iv1cmNwW/ZIyZbTOzriAEm83s382sNEPz7hjySA2po8PMrh3r97n7gLuXuvv2iRxXJBMU/JJp73L3UuAs4Bzg7zIx0yB4S4N5bx+sI3jcdfT4ZpafibpEoqDgl0i4+y7gV8ACADM7yczuN7N9ZrbZzP58cFwzW2pmTWbWFvxS+NqQz84zsyfN7ICZPWdmF42nnqDL5Cdm9iMzaweuM7M3mdlTwXfvNrN/NbOCYPx8M3Mzawze/zD4/Fdm1m5mfzCzOWMdN/j8MjN70cwOmtk3zey/zexDo1yOK83s+aDm35jZG4Z89lkzeyX4O74w+LcK/oarhvx9/3k8f0PJHQp+iYSZzQSWAc8Gg34E7AROAq4C/q+ZXRx89g3gG+5eDpwM3B18xwzgF8CXgGrgr4F7zax2nGW9B/gPoAL4CdAPfAKoAS4ALgU+eozpPwj8fVDLduAfxzqumdWRXr6/Cea7FVg6muLNbD7wQ+B/ArXAI8B/mVmBmb0xqP2s4O94WTBfgG8C/xwMnwfcM5r5Se5S8Eum/dzMDgBPAL8jHfAzgTcDf+vu3e6+GrgduD6Ypg+YZ2Y17t7h7k8Fw68Dfunuv3T3lLs/DDSRblDG4wl3/6/gu7rcfaW7P+3u/e6+BbgNeOsxpr/H3ZvcvQ+4C1g8jnEvB1a7+33BZ18H9o6y/quB+939N8G0NwPlwLmkG7Ek8EYzy3f3rcEyQfrve4qZTXX3dnd/epTzkxyl4JdMu9LdK919trv/lbt3kd7K3+fu7UPGexmYEbz+MHAq8IKZrTSzy4Phs4H3B90aB4IG5c1A/Thr2zH0jZmdZma/MLM9ZtYG/APprfCR7Bny+hBwrB3XI4170tA6PH0VxZ2jqH1w2peHTJsKpp3h7huBT5FehpagS2t6MOqfAacDG81shZmNt+GUHKHgl2zwClBtZmVDhs0CdgG4+yZ3vwaoA74C3GNmJaQD8gdBQzL4KHH3m8dZx9GXqv0OsA6YF3SD/G/Axvndo7UbaBh8Y2bGkQbweF4h3RgOTpsXfNfg3/GH7n4BMAdIAF8Ohm9096tJ/31vId1dljzxRZFspeCXyLn7DuBJ4MtmljSzM0hv5d8FYGbXmVltsAV7IJhsgHR/9rvM7J3BsfJJM7vIzBqGm884lAEHgc6g//xY/fsT5QHgLDN7V3Bk0SdI99ePxt3Au4O/QQHp/QTtwNNmNt/M/sjMioCu4DEAYGbXB91oKdLL60BqYhdLsomCX7LFNUAj6a3WnwGfD/rsIb1T9Xkz6yC9o/fqYF/ADuAK4LNAK+lfAH/DxP27/hRwA+nw/A7pHb6hcvdm4APA14BXSe/MfhboGcW0z5Ou91bSf49LgXcH/f1FwD+R3l+wB6jiyKG0y4ANwdFMXwU+4O69E7hYkmVMN2IRyV5mliDdGF7l7o9HXY9MDtriF8kyZnapmVUE3TJ/T/qInBURlyWTiIJfJPu8GdhCulvmUtJHQh23q0dktNTVIyISM9riFxGJmZy4EFVNTY03NjZGXYaISE555pln9rr76w4Hzongb2xspKmpKeoyRERyipm9PNxwdfWIiMSMgl9EJGYU/CIiMaPgFxGJGQW/iEjMKPhFRGJGwS8iEjOTOvif3LyXbz22OeoyRESyyqQO/t+92MpXf72RbXs7oy5FRCRrTOrg//Bb5lCQyOPWx16KuhQRkawxqYO/rizJNUtnce+qnew60BV1OSIiWWFSBz/AjRfOxQy+8ztt9YuIQAaCP7gJ9rNm9kDwvtrMHjazTcFzVZjzP6mymKvObuDHK3fQ0tYd5qxERHJCJrb4PwFsGPL+JuBRdz8FeDR4H6q/fOs8BlLObb/fEvasRESyXqjBb2YNwB8Dtw8ZfAWwPHi9HLgyzBoAZk2dwrsXncR/rNhOV+9A2LMTEclqYW/x/wvwaSA1ZNg0d98NEDzXDTehmd1oZk1m1tTa2nrChbzvrAYO9Q7wxOa9J/xdIiK5LLTgN7PLgRZ3f2Y807v7be6+xN2X1Na+7gYyY3bu3GrKkvk89PyeE/4uEZFcFuYduC4A3m1my4AkUG5mPwSazaze3XebWT3QEmINhxUk8rj4tDoe2dBMKuXk5VkmZisiknVC2+J398+4e4O7NwJXA79x9+uA+4EbgtFuAO4Lq4ajnT+vhv2H+tiiM3lFJMaiOI7/ZuASM9sEXBK8z4izZlUC8Oz2/ZmapYhI1slI8Lv7Y+5+efD6VXe/2N1PCZ73ZaIGgLk1pZQl81m940CmZikiknUm/Zm7Q+XlGYsaKhX8IhJrsQp+gEUzK3hhTzs9/TqeX0TiKXbBP6+ulIGUs2OfLtomIvEUu+BvnFoCoGv0i0hsxTf4X1Xwi0g8xS74q0oKqSguYKu2+EUkpmIX/ACNNSXa4heR2Ipl8M+ZOoVtew9FXYaISCRiGfyzp5bwysEuHdIpIrEUy+A/qTKJO7S09URdiohIxsUy+KeVJwFo1q0YRSSGYhn89RXFAOxR8ItIDMUy+KcHW/x7Dir4RSR+Yhn85cX5JAvyFPwiEkuxDH4zY3p5Ul09IhJLsQx+SO/g1c5dEYmj2Ab/9Apt8YtIPMU3+MuTNLf14O5RlyIiklGxDf5p5Ul6+1PsP9QXdSkiIhkV2+CfXqFDOkUknkILfjNLmtkKM3vOzJ43sy8Gw79gZrvMbHXwWBZWDceis3dFJK7yQ/zuHuBt7t5hZgXAE2b2q+Czr7v7V0Oc93HVD27xK/hFJGZCC35P7zXtCN4WBI+s2ZNaW1aEGexWV4+IxEyoffxmljCz1UAL8LC7Px189HEzW2Nmd5pZ1QjT3mhmTWbW1NraOuG1FSTyqCktolnBLyIxE2rwu/uAuy8GGoClZrYAuBU4GVgM7AZuGWHa29x9ibsvqa2tDaU+nb0rInGUkaN63P0A8Bhwqbs3Bw1CCvgusDQTNQxHZ++KSByFeVRPrZlVBq+LgbcDL5hZ/ZDR3gOsC6uG45leUaQtfhGJnTCP6qkHlptZgnQDc7e7P2BmPzCzxaR39G4DPhpiDcc0vTzJgUN9dPcNkCxIRFWGiEhGhXlUzxrgzGGGXx/WPMdq6LH8s6eWRFyNiEhmxPbMXdDZuyIST/EO/nKdxCUi8RPv4K/QZRtEJH5iHfxlyQJKChPsOdgTdSkiIhkT6+AHmFaRZE9bV9RliIhkTOyDf3p5Ujt3RSRWFPzBnbhEROIi9sE/rSJ92YZUKmsuHCoiEqrYB399RZL+lLO3Q1v9IhIPsQ/+mdVTANi+71DElYiIZEbsg3+Wgl9EYib2wd9QVYwZvPyqgl9E4iH2wV+Un+CkimJt8YtIbMQ++AFmViv4RSQ+FPzA7OoSdfWISGwo+IFZU6ewt6OHzp7+qEsREQmdgh+YU5O+CcvWvZ0RVyIiEj4FP3DqtFIANrW0R1yJiEj4FPzA7KklFCSMTc0dUZciIhI6BT9QkMhjTk0JLyr4RSQGQgt+M0ua2Qoze87MnjezLwbDq83sYTPbFDxXhVXDWJxSV8ZmdfWISAyEucXfA7zN3RcBi4FLzew84CbgUXc/BXg0eB+5eXWlbN93iO6+gahLEREJVWjB72mDfScFwcOBK4DlwfDlwJVh1TAWp00vI+XwYrO2+kVkcgu1j9/MEma2GmgBHnb3p4Fp7r4bIHiuG2HaG82sycyaWltbwywTgAUzKgBYs/Ng6PMSEYlSqMHv7gPuvhhoAJaa2YIxTHubuy9x9yW1tbXhFRloqCqmckoB63Yp+EVkcsvIUT3ufgB4DLgUaDazeoDguSUTNRyPmbFwRgVrFfwiMsmFeVRPrZlVBq+LgbcDLwD3AzcEo90A3BdWDWO1YEYFG/e0aweviExq+SF+dz2w3MwSpBuYu939ATP7A3C3mX0Y2A68P8QaxmRRQwX9Kef5V9o4e3ZWHGUqIjLhQgt+d18DnDnM8FeBi8Oa74k4a1Y67Fe9vF/BLyKTls7cHaKuPMnM6mKeeXl/1KWIiIRGwX+UJbOraXp5P+4edSkiIqFQ8B/l7NlV7O3oYce+rqhLEREJhYL/KIN9+00v74u4EhGRcCj4j3LqtDLKivJpUj+/iExSCv6jJPKMM2dXsUrBLyKTlIJ/GGfPqmJjczsHu/qiLkVEZMIp+IdxTmMV7rBqu7b6RWTyUfAP48xZVeTnGSu3ageviEw+Cv5hFBcmWDCjghUKfhGZhBT8I1g6p5o1Ow/qgm0iMuko+EewtLGa3oEUz+04EHUpIiITSsE/giWN6RO51N0jIpONgn8ElVMKecO0MlZsU/CLyOSi4D+GpXOqWfXyfvoHUlGXIiIyYRT8x3DOnGo6ewdYv7st6lJERCaMgv8YljZWA+rnF5HJRcF/DNMrksyqnsJK9fOLyCSi4D+OcxqrWblNN2YRkclDwX8cS+dUsa+zl5daO6IuRURkQoQW/GY208x+a2YbzOx5M/tEMPwLZrbLzFYHj2Vh1TARBm/AvnrHwYgrERGZGGFu8fcDn3L3+cB5wMfM7PTgs6+7++Lg8csQazhhc2tLKSlMsHanzuAVkclhVMFvZp8ws3JLu8PMVpnZO441jbvvdvdVwet2YAMw48RLzqxEnvHGGRU8t1Nb/CIyOYx2i/9/uHsb8A6gFvgz4ObRzsTMGoEzgaeDQR83szVmdqeZVY0wzY1m1mRmTa2traOdVSgWNVSwfncbfTqRS0QmgdEGvwXPy4B/d/fnhgw79oRmpcC9wCeDxuNW4GRgMbAbuGW46dz9Nndf4u5LamtrR1lmOBY2VNLbn+LF5vZI6xARmQijDf5nzOwh0sH/azMrA467+WtmBaRD/y53/ymAuze7+4C7p4DvAkvHV3rmLGqoAGCNuntEZBIYbfB/GLgJOMfdDwEFpLt7RmRmBtwBbHD3rw0ZXj9ktPcA68ZUcQRmVU+hPJmv4BeRSSF/lOO9CVjt7p1mdh1wFvCN40xzAXA9sNbMVgfDPgtcY2aLAQe2AR8dc9UZZmac0VDJGh3ZIyKTwGiD/1ZgkZktAj5Nekv++8BbR5rA3Z9g+P0AWX345kjOaKjgtt9vobtvgGRBIupyRETGbbRdPf2evmbBFcA33P0bQFl4ZWWfMxoq6E85G3SlThHJcaMN/nYz+wzprptfmFmCdD9/bJzRUAnA2l3q5xeR3Dba4P8A0EP6eP49pE/E+ufQqspC9RVJakoLtYNXRHLeqII/CPu7gAozuxzodvfvh1pZltEOXhGZLEZ7yYY/AVYA7wf+BHjazK4Ks7BstHBGBZtbOujs6Y+6FBGRcRvtUT2fI30MfwuAmdUCjwD3hFVYNjqjoYKUw/OvtLF0TnXU5YiIjMto+/jzBkM/8OoYpp00Fh4+g1fdPSKSu0a7xf+gmf0a+FHw/gPk6PH4J6KuLEl9RVJH9ohIThtV8Lv735jZ+0ifjWvAbe7+s1Ary1ILZ1SwVkf2iEgOG+0WP+5+L+kLrsXaGQ0VPLS+mbbuPsqTsTqVQUQmiWP205tZu5m1DfNoN7NYnsI6eCLXOnX3iEiOOuYWv7vH6rIMo7FwRnoH79qdBzn/5JqIqxERGbvYHZlzoqpKCplZXcwabfGLSI5S8I/DGTN0Bq+I5C4F/zic0VDBjn1d7O/sjboUEZExU/CPw+ETudTdIyI5SME/DosaKknkGSu37ou6FBGRMVPwj0NJUT4LZlSwQsEvIjlIwT9O586pZvWOA3T3DURdiojImCj4x2lpYzW9AylWbd8fdSkiImMSWvCb2Uwz+62ZbTCz583sE8HwajN72Mw2Bc9VYdUQpqVzqylIGI9tbI26FBGRMQlzi78f+JS7zwfOAz5mZqcDNwGPuvspwKPB+5xTnizgvLlTeWR9c9SliIiMSWjB7+673X1V8Lod2ED6Xr1XAMuD0ZYDV4ZVQ9guOX0aW/Z2srmlI+pSRERGLSN9/GbWCJwJPA1Mc/fdkG4cgLoRprnRzJrMrKm1NTu7U94+fxoAD2urX0RySOjBb2alpC/n/El3H/UVPd39Nndf4u5LamtrwyvwBJxUWcyCGeU8vH5P1KWIiIxaqMFvZgWkQ/8ud/9pMLjZzOqDz+uBlpGmzwWXzJ/OszsO0NreE3UpIiKjEuZRPQbcAWxw968N+eh+4Ibg9Q3AfWHVkAmXnD4Nd3hkg7p7RCQ3hLnFfwFwPfA2M1sdPJYBNwOXmNkm4JLgfc6aX1/G7KlT+NU6dfeISG4Y9a0Xx8rdnyB9f97hXBzWfDPNzLhsQT23P76FA4d6qZxSGHVJIiLHpDN3J8CyhdPpTzm/XKutfhHJfgr+CbBwRgXz68v53pNbcfeoyxEROSYF/wQwMz785jm82NzBE5v3Rl2OiMgxKfgnyLsW1VNTWsSdT2yNuhQRkWNS8E+QovwE1583m99ubNUlHEQkqyn4J9C1580iWZDHLQ9tjLoUEZERKfgnUE1pER+7aB6/WreHJ19SX7+IZCcF/wT78wvnUltWxB2Pq69fRLKTgn+CJQsSfGDJTH6zsYWd+w9FXY6IyOso+ENwzbmzMOAnK3dEXYqIyOso+EMwo7KYP3pDHT9euYO+gVTU5YiIvIaCPyTXnjeL1vYeHtTF20Qkyyj4Q/LWU+s4pa6Urzz4Al29A1GXIyJymII/JIk840tXLmDn/i6++ZtNUZcjInKYgj9E586dyvvOauC7j29hU3N71OWIiAAK/tB9dtlpFBckuOWhF6MuRUQEUPCHbmppETec38iv1+/RNXxEJCso+DPgQ+c3ksxP8PVHtNUvItFT8GfA1NIibrxwLr9Ys5sVW/dFXY6IxJyCP0P+4q0nU1+R5B8eeJ7bH9/Cz5/dRb9O7hKRCIQW/GZ2p5m1mNm6IcO+YGa7zGx18FgW1vyzTXFhgpsuO411u9r40i828MmfrOYvfvgMAyndqlFEMis/xO/+HvBvwPePGv51d/9qiPPNWu9edBKrdxzg1GlldPb086VfbODbv3uJj/3RvKhLE5EYCS343f33ZtYY1vfnIjPj8+964+H3P3t2F09teVXBLyIZFUUf/8fNbE3QFVQ10khmdqOZNZlZU2traybry5h5daVs3dsZdRkiEjOZDv5bgZOBxcBu4JaRRnT329x9ibsvqa2tzVR9GTWnpoRdB7ro7tO1fEQkczIa/O7e7O4D7p4CvgsszeT8s82cmhLcYfs+3bBFRDIno8FvZvVD3r4HWDfSuHEwt6YUgC2t6u4RkcwJbeeumf0IuAioMbOdwOeBi8xsMeDANuCjYc0/F8ypLQFgy15dykFEMifMo3quGWbwHWHNLxeVFuUzrbyIDbt15U4RyRyduRuxi+dP4+H1ezjY1Rd1KSISEwr+iF1zziy6+1Lct3pX1KWISEwo+CO2sKGCxTMr+ddHN7OvszfqckQkBhT8WeDL713Iwa5e3nfrkzy4bnfU5YjIJKfgzwLz68v59nVnU5Sfx1/etYq7V+6IuiQRmcQU/Fni4vnT+PnHLuDCU2r59L1r+MFTL0ddkohMUgr+LJIsSHDbn57N2+fX8fc/X8fnfraWpm26cYuITCwFf5Ypyk/wrWvP5qqzG/jPpp1c9e0/8JHlK9nUrGP9RWRimHv23whkyZIl3tTUFHUZGdfVO8D3ntzGt367mc7efj7ylrl85rLTMLOoSxORHGBmz7j7kqOHh3kjFjlBxYUJ/vKik/nAOTP5yq9e4Lbfb2FLayd/fMZ03nNmQ9TliUiOUvDngOqSQm5+30IqSwq4e+UOHtnQzLpdbXxu2Xzy8oxUysnL068AERkdBX+OMDM+c9l8Pv3O0/jHB9ZzxxNb2dzSQd9Ail0HuvjPj76JkqJ8dh/sZl5dadTlikgWU/DnmESe8fl3nU5DVTH/9tvN9A84AynnujueJs+MTS0d3PzehUwtLaSiuIADh/rYvu8Qf/qmRhL6VSAiaOduTuvtT+E4T23Zx6fveY4Dh/qYUVnMlmFu5/ih8xv53B/PpyChA7lE4mKknbsK/kmiu2+Atu4+ivITrNi6j6mlhbR19ZFnxm9eaOF7T25jVvUUvvunS3jD9LKoyxWRDFDwx5i78+iGFj7387W0tPdQWVzAv1x9JheeUkNrew+1ZUWHDxEdSDlbWjuYV1eqw0ZFcpwO54wxM+Ptp0/jtPoy7l65g4fWN/Ohf19BfXmSVw52M3vqFD7ylrm0tHVzzzM72X2wm29dexbLFtYf/8tFJOdoiz+G2rv7uP3xrazddZCzZlXy4PN7WLerDTO48JRaXmxuZ1b1FH7y0TdFXaqInAB19ciIBlLO+lfaaKgqpqqkkFsfe4mvPPgCl59Rz3M7D/DNa85i8czKqMsUkTEaKfh1iIeQyDMWNlRQVVIIwAeXzuJtp9Xx2MZWduzr4p5ndJlokckktOA3szvNrMXM1g0ZVm1mD5vZpuC5Kqz5y/hVTCngzg+dw7ovvpNL3zidR9a3kEpl/y9DERmdMLf4vwdcetSwm4BH3f0U4NHgvWSxS06fxp62bppe3h91KSIyQUILfnf/PXD0xeSvAJYHr5cDV4Y1f5kYbz99GnVlRfzVXat4cvNecmGfkIgcW6b7+Ke5+26A4LlupBHN7EYzazKzptbW1owVKK9VUVzAf/z5uRTl5/HB25/msm88zk9X7WTn/kNqBERyVKhH9ZhZI/CAuy8I3h9w98ohn+939+P28+uonuh19w1w76qd/PCp7WzY3QbAopmVXL6wHjOoKS3i3LnV1FcUR1ypiAzKlhO4ms2s3t13m1k90JLh+cs4JQsSXHvubK45ZxaPb97LpuZ2vv+Hl/k/v9zwmvHecfo03nd2A2VF+fQOpDhtejnTK5IRVS0iw8l08N8P3ADcHDzfl+H5ywnKyzPeemotbz21lo+8ZS77O3sB2NPWza/W7ubO/97GQ+ubj4xv0FA1hcaaEpYtmM7li06itEgnjItEKbSuHjP7EXARUAM0A58Hfg7cDcwCtgPvd/fj3k1cXT2541BvPy82d9DTN4CZ8fimVrbvO8TaXQfZ0pq+augbppUxtbSQ2rIi3r3oJJIFCcqTBSyYUa7rA4lMIJ25K5Fyd1Zs3cfKbft4YvNeunoH2LK3k/bu/sPj5OcZs6dO4fyTayjKz+P9S2Zy6rT0TWXUIIiMnYJfsk5X7wBrdx2kfyDFjv2H2Lr3EI9tbGH7vkP0Dzi9AykASovymV9fRm1ZEY1TSyjKT3De3GpqyoqYW1OiRkFkBAp+yRnuTmtHD7/Z0MIrB7rY29nLSy0dvHKwi137uwAYPJG4prSIs2dX8k9XLaKiuCDCqkWyT7Yc1SNyXGZGXVmSq5fOet1n7s6rnb2s23WQPQe7WbltP//13Ctce/tTvHvRScyvL+cN08uoKSnSDehFRqAtfsl5D67bwz8+sJ5dB7oOD0vkGTXBDuTa0qLDF6CrK0syozLJ9IpiSooSzKkpoSxZQEHCKMjLU2Mhk4q2+GXSunTBdC5dMJ39nb1s2N3Gi83ttHb00Nqefuzt6OXF5o7DXUh9AyNv7EwvTzKregp15UX09KcoS+ZTX5Gkakoh5ckCyovzg+cCKooLqCoppKQwof0MklMU/DJpVJUUcv68Gs6fVzPiOKmUs7ejhz1t3bR19bP11U66ewfoHUjR0zfArgPd7Nh3iHW7DpIsSNDW1Udzew8Dx7g6aWF+HtVTCqkqKWRqSfq5KD+PqikFnFRZTHmygEc2NLO5pYPpFUlqy4ooLcqnpCg//VyYOPI6eJQlg88L8ykpSpCf0BXUZeIo+CVW8vKMuvIkdeXps4nffMrIjcSgVMpp7+mnvbuPtq5+2rr7aOvq40BXH/s7e9l3qDf9HDx27j9ET3+KfZ299PQfOTLpTSdPpaWtmy2tnXT29tPR3U//KC93XZSfR0lRPsn8PJKFCZL5CZIFeSQLEsEjj2R+gqKCBMUFQz8LnvMTFAWvi4dOU3Dku4qCYYWJPP2CmeQU/CLHkZdnVARdO4zhDhIDKaetq4/9h3qpKSuiPPnao47cnZ7+FJ09/XT2DNDR059uEHr6g2H9dPQMBM/p9919Kbr7B+jpG0i/7hugrbuP7r4UXb0D9PQfGT7aRuV1y2scaVDy041D0ZDGJVmQR3Fh4nBDc3TjUjQ4TX4eRfnBc8GR14c/GzKsKD9Pv2oySMEvEpJEnlEVdP0Mx8wOB+zU0omff/9Aiu7+dCPQPaSheM3r/tcO7zlq/K4hr9ONygB7O/pfN21PX+rweRfjlZ9nQYNwpDEoGvylMqRReV1jclQDMjh9cpjveV2jFAyL268cBb/IJJWfyKM0kZexayMNpJze/nQD0dOfoufwr5Mhw4L3R4YfGTbY6PQc9R2Dv2I6e/rZ13lkmu6+9H6Z9PsTa3TMoDARNAJHNSyFhxuP1zc8hYkjDU369ZHPC/OPfn1Uo3ZUA5WfZxlrfBT8IjIhEnlGcWGC4sJExuftnj7T+3DjMbRRGbEROtJwdPcNBI3WkemGvu/tT3fFvdqRCuZzZB6Djd2J3p3UjNc0LIONxZffewZL51RPzB8qoOAXkZxnZkFgJl63LyUT3J3+w794jmo4+lL0DgxtjF77y+d1jU7f4FFm6fdh/GJT8IuInCAzS58EmMijpCjqao5Pu9FFRGJGwS8iEjMKfhGRmFHwi4jEjIJfRCRmFPwiIjGj4BcRiRkFv4hIzOTEHbjMrPix7UcAAAW4SURBVBV4eZyT1wB7J7CcKGlZspOWJTtpWWC2u9cePTAngv9EmFnTcLcey0ValuykZclOWpaRqatHRCRmFPwiIjETh+C/LeoCJpCWJTtpWbKTlmUEk76PX0REXisOW/wiIjKEgl9EJGYmdfCb2aVmttHMNpvZTVHXM1Zmts3M1prZajNrCoZVm9nDZrYpeK6Kus7hmNmdZtZiZuuGDBuxdjP7TLCeNprZO6Op+vVGWI4vmNmuYL2sNrNlQz7LyuUAMLOZZvZbM9tgZs+b2SeC4bm4XkZalpxbN2aWNLMVZvZcsCxfDIaHt17cfVI+gATwEjAXKASeA06Puq4xLsM2oOaoYf8E3BS8vgn4StR1jlD7hcBZwLrj1Q6cHqyfImBOsN4SUS/DMZbjC8BfDzNu1i5HUF89cFbwugx4Mag5F9fLSMuSc+sGMKA0eF0APA2cF+Z6mcxb/EuBze6+xd17gR8DV0Rc00S4AlgevF4OXBlhLSNy998D+44aPFLtVwA/dvced98KbCa9/iI3wnKMJGuXA8Ddd7v7quB1O7ABmEFurpeRlmUk2bws7u4dwduC4OGEuF4mc/DPAHYMeb+TY//DyEYOPGRmz5jZjcGwae6+G9L/+IG6yKobu5Fqz8V19XEzWxN0BQ3+BM+Z5TCzRuBM0luXOb1ejloWyMF1Y2YJM1sNtAAPu3uo62UyB78NMyzXjl29wN3PAi4DPmZmF0ZdUEhybV3dCpwMLAZ2A7cEw3NiOcysFLgX+KS7tx1r1GGGZdXyDLMsOblu3H3A3RcDDcBSM1twjNFPeFkmc/DvBGYOed8AvBJRLePi7q8Ezy3Az0j/nGs2s3qA4LklugrHbKTac2pduXtz8B81BXyXIz+zs345zKyAdFDe5e4/DQbn5HoZbllyed0AuPsB4DHgUkJcL5M5+FcCp5jZHDMrBK4G7o+4plEzsxIzKxt8DbwDWEd6GW4IRrsBuC+aCsdlpNrvB642syIzmwOcAqyIoL5RGfzPGHgP6fUCWb4cZmbAHcAGd//akI9ybr2MtCy5uG7MrNbMKoPXxcDbgRcIc71EvUc75L3ly0jv7X8J+FzU9Yyx9rmk99w/Bzw/WD8wFXgU2BQ8V0dd6wj1/4j0T+0+0lsoHz5W7cDngvW0Ebgs6vqPsxw/ANYCa4L/hPXZvhxBbW8m3SWwBlgdPJbl6HoZaVlybt0AZwDPBjWvA/53MDy09aJLNoiIxMxk7uoREZFhKPhFRGJGwS8iEjMKfhGRmFHwi4jEjIJfJARmdpGZPRB1HSLDUfCLiMSMgl9izcyuC66FvtrMvhNcLKvDzG4xs1Vm9qiZ1QbjLjazp4ILgP1s8AJgZjbPzB4Jrqe+ysxODr6+1MzuMbMXzOyu4GxTzOxmM1sffM9XI1p0iTEFv8SWmc0HPkD6YniLgQHgWqAEWOXpC+T9Dvh8MMn3gb919zNInx06OPwu4P+5+yLgfNJn+kL6ipGfJH399LnABWZWTfpSAm8MvudL4S6lyOsp+CXOLgbOBlYGl8S9mHRAp4CfBOP8EHizmVUAle7+u2D4cuDC4HpKM9z9ZwDu3u3uh4JxVrj7Tk9fMGw10Ai0Ad3A7Wb2XmBwXJGMUfBLnBmw3N0XB483uPsXhhnvWNc1Ge4SuYN6hrweAPLdvZ/0FSPvJX1jjQfHWLPICVPwS5w9ClxlZnVw+B6ns0n/v7gqGOeDwBPufhDYb2ZvCYZfD/zO09eA32lmVwbfUWRmU0aaYXD9+Ap3/yXpbqDFYSyYyLHkR12ASFTcfb2Z/R3pu5zlkb4C58eATuCNZvYMcJD0fgBIXxr320GwbwH+LBh+PfAdM/uH4Dvef4zZlgH3mVmS9K+F/zXBiyVyXLo6p8hRzKzD3UujrkMkLOrqERGJGW3xi4jEjLb4RURiRsEvIhIzCn4RkZhR8IuIxIyCX0QkZv4/L/xRWPe4V3oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = net(torch.FloatTensor(X_test))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "track_loss\n",
    "x = [i for i in range(epochs)]\n",
    "plt.plot(x, track_loss)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Pose Training loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  Drinking Reaching Behind Safe driving Talking to Passenger Texting - left Drinking Safe driving Talking on the phone - right Reaching Behind Safe driving\n"
     ]
    }
   ],
   "source": [
    "classes = ('Safe driving', 'Texting - right', 'Talking on the phone - right', 'Texting - left',\n",
    "           'Talking on the phone - left', 'Operating the radio', 'Drinking', 'Reaching Behind', 'Hair and makeup', 'Talking to Passenger')\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8803304308997544\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i] == predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Safe driving : 92 %\n",
      "Accuracy of Texting - right : 93 %\n",
      "Accuracy of Talking on the phone - right : 90 %\n",
      "Accuracy of Texting - left : 93 %\n",
      "Accuracy of Talking on the phone - left : 91 %\n",
      "Accuracy of Operating the radio : 97 %\n",
      "Accuracy of Drinking : 81 %\n",
      "Accuracy of Reaching Behind : 97 %\n",
      "Accuracy of Hair and makeup : 57 %\n",
      "Accuracy of Talking to Passenger : 79 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    label = Y_test[i]\n",
    "    if Y_test[i] == predicted[i]:\n",
    "        class_correct[label] += 1\n",
    "    class_total[label] += 1\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[427,   1,   1,  10,   1,   4,   0,   0,   2,  14],\n",
       "       [  3, 471,   3,   0,   1,   1,  18,   1,   2,   2],\n",
       "       [  0,   0, 443,   0,   0,   0,  15,   5,  24,   0],\n",
       "       [  7,   0,   2, 446,  14,   2,   0,   1,   1,   5],\n",
       "       [  4,   0,   0,  17, 396,   3,   0,   1,  13,   0],\n",
       "       [  4,   1,   4,   3,   0, 433,   0,   0,   1,   0],\n",
       "       [  0,  21,  23,   0,   0,   0, 363,   1,  36,   0],\n",
       "       [  1,   2,   2,   0,   0,   1,   0, 409,   1,   2],\n",
       "       [ 16,  13,  70,   1,  18,   0,  38,  15, 230,   2],\n",
       "       [ 64,   5,   0,   3,   1,   5,   0,   3,   1, 325]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(Y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\Son Do/.cache\\torch\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [01:18<00:00, 7.09MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "model.classifier = nn.Sequential(*features)\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../input/driver_imgs_list.csv' does not exist: b'../input/driver_imgs_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fb1c099dc5d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/driver_imgs_list.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/driver_imgs_list.csv' does not exist: b'../input/driver_imgs_list.csv'"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('../input/driver_imgs_list.csv')\n",
    "dataset.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
